{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Performance Assessment Indicators (PAIs)\r\n",
    "\r\n",
    "#### Introduction\r\n",
    "\r\n",
    "The 01 notebooks guide users through the basics on how to download data from the wapor portal using the class **WaporRetrieval** and how to calculate statistics using the retrieved files. \r\n",
    "\r\n",
    "The goal of the 02 notebook is to show an example of how many of the functions you aready used can be combined together into a pipeline to achieve a specific result of value.\r\n",
    "\r\n",
    "Pipeline: a pipeline is a set of steps carried out one after the other in order to achieve a specific result. It is a process that is also often automated as the steps are \r\n",
    "standardised allowing for quick and repeated use. \r\n",
    "\r\n",
    "In this case the pipeline is made up of a set of classes and functions from the waterpip package organized to calculate performance assessment indicators (PAI's). <br>\r\n",
    "PAI's are statistics that have been developed specifically to provide information on agricultural productivity and water use effeciency from information taken from sattelite imagery.\r\n",
    "\r\n",
    "#### Performance Assessment Indicators (PAIs) in detail\r\n",
    "\r\n",
    "Increasing competition for and limited availability of water and land resources puts a serious constraint on agricultural production systems. Sustainable land and water management practices will be critical to expand production efficiently and address food insecurity while limiting impact on the ecosystem. This requires a good understanding of how agricultural systems are performing and their potential for improvement. Variables affecting the performance of agricultural systems are both biophysical (climate, soil, topography) and socio-ecological (market, infrastructure, farm management, available inputs). The proposed approach is built on performance assessment indicators that look at satellite observations of the actual crop production and water consumption from the WaPOR database. The indicators focus on the actual performance of the agriculture system and the underlying biophysical factors, but as a satellite-based system it cannot provide information on underlying socio-ecological variables.\r\n",
    "\r\n",
    "The approach is based on a number of Performance Assessment Indicators (PAIs) that are derived from FAO WaPOR data on crop, water consumption and growth. The indicators estimate Water Productivity (WP) and Land Productivity (yield) perfomances at various levels for specific crop types for a selected area and time period. \r\n",
    "\r\n",
    "### **Steps**:<br>\r\n",
    "\r\n",
    "1. Importing of the modules and functions needed<br><br> \r\n",
    "\r\n",
    "2. Get a download api token from the WAPOR portal if not done previously, see notebook *01A_waterpip_download_basics* for details <br><br> \r\n",
    "\r\n",
    "3. activating/initiating the class **WaporAnalysis**: This python class holds the pipeline used to calculate \r\n",
    "the PAI's and is built on top of **WaporRetrieval** allowing the user to interact with the WAPOR portal and retrieve information from it.<br> \r\n",
    "\r\n",
    "    - NOTE: **WaporRetrieval** is built on top of the class **WaporAPI** originally written by Bich Tran at IHE Delft \r\n",
    "    for the various open source WAPOR packages released by IHE DELFT.<br><br>  \r\n",
    "\r\n",
    "4. Creation of raster and shapefile mask for use during the analysis.<br><br>  \r\n",
    "\r\n",
    "5. calculation of a relative evapotranspiration a PAI.<br><br> \r\n",
    "\r\n",
    "6. Export the calculated PAI statistics too a shapefile<br><br> \r\n",
    "\r\n",
    "7. Visualise the data<br><br> \r\n",
    "\r\n",
    "8. Rinse and Repeat<br><br> \r\n",
    "\r\n",
    "NOTE: If this is your first time running this please read the instructions below and follow the steps, otherwise feel free to use the notebook as you wish. If you have not run any of the notebooks before i recommend you start with the 01 series such as *01A_waterpip_download_basics*. \r\n",
    "\r\n",
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: Reading the following is not required but it is advised\r\n",
    "\r\n",
    "## A quick guide to the waterpip package scripts and the automatic folder structure used in the classes.\r\n",
    "\r\n",
    "#### Scripts:\r\n",
    "\r\n",
    "When you run the functions in some of the scripts found in this package, specifically the ones found in the classes the files used/made are stored and retrieved using a standardised process. That means the file names and paths as well as the folder names and paths are standardised. This is neccescary to automate alot of the process when using the pipelines provided. \r\n",
    "\r\n",
    "This standardised structure is specified in the class **WaporStructure** found in the file *waterpip\\scripts\\structure\\wapor_structure.py* if you want to take a \r\n",
    "closer look. \r\n",
    "\r\n",
    "to put it simply all the scripts containing classes follow the standardised file and folder structure set by **WaporStructure**:\r\n",
    "\r\n",
    "- **WaporStructure**: *waterpip\\scripts\\structure\\wapor_structure.py*\r\n",
    "- **WaporRetrieval**: *waterpip\\scripts\\retrieval\\wapor_retrieval.py*\r\n",
    "- **WaporAnalysis**: *waterpip\\scripts\\analysis\\wapor_analysis.py*\r\n",
    "\r\n",
    "while all the general functions (tools) that support these classes can also be used outside them however the user wants: \r\n",
    "\r\n",
    "- *waterpip\\scripts\\support\\raster.py*\r\n",
    "- *waterpip\\scripts\\support\\vector.py*\r\n",
    "- *waterpip\\scripts\\support\\statistics.py*\r\n",
    "\r\n",
    "so feel free to use them however you want\r\n",
    "\r\n",
    "#### Automatic folder structure:\r\n",
    "\r\n",
    "all downloaded and created files are stored in subdirectories under the wapor directory specified on class activation. File names are also automatcially made using \r\n",
    "the inputs given by the user. \r\n",
    "\r\n",
    "The main folder stucture is as follows:\r\n",
    "\r\n",
    "- **main directory** : working directory specified by the user <br>\r\n",
    "\r\n",
    "    - *<user_specified_waterpip_directory>*<br><br> \r\n",
    "\r\n",
    "- **metadata folder** : directory made to hold general wapor information (metadata) that is used during any downloads and could be useful for the user to check out. like the wapor catalogue <br>\r\n",
    "\r\n",
    "    - *<user_specified_waterpip_directory>\\metadata*<br><br> \r\n",
    "\r\n",
    "- **wapor level** : directory specific to the project or analysis the user is carrying out. In most cases it is suggested that this relates to a specific area/region/boundingbox <br>\r\n",
    "\r\n",
    "    - *<user_specified_waterpip_directory>\\<user_specified_project_name>*<br><br> \r\n",
    "\r\n",
    "- **wapor level** : wapor level specific directory within the project name directory used to split the data between wapor levels. Each analysis is wapor specific (1,2 or 3) <br>\r\n",
    "\r\n",
    "    - *<user_specified_waterpip_directory>\\<user_specified_project_name>*\\l<user_specified_wapor_level><br><br> \r\n",
    "\r\n",
    "in each wapor level directory there are 6 standard sub directories used to organize and hold any data created:\r\n",
    "\r\n",
    "    - *00_reference*: reference data is stored here (masks and related shapefiles etc) (tiffs, csv's and shp's)\r\n",
    "    - *01_download*: raw donwloaded rasters are stored here (tiff's and vrt's)\r\n",
    "    - *02_processed*: processed rasters are stored here (tiff's and vrt's)\r\n",
    "    - *03_masked*: masked rasters are stored here  (tiff's and vrt's)\r\n",
    "    - *04_analysis*: analysis output (halfway products) are stored here (tiff's and vrt's, shp's and xls)  \r\n",
    "    - *05_results*: results (products) are stored here (tiff's and vrt's, shp's and xls) \r\n",
    "    - *06_images*: any image results are stored here (png's, jpeg's)\r\n",
    "\r\n",
    "- NOTE:<br><br> \r\n",
    "\r\n",
    "- folders 01 and 02 are input folders and data is stored there according to wapor naming standards.<br><br> \r\n",
    "\r\n",
    "- folders 00 and 03 -> 06 are output folders and all data is stored there in subfolders according to the mask provided during each analysis\r\n",
    "\r\n",
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import modules/libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "from datetime import datetime\r\n",
    "from waterpip.scripts.analysis.wapor_analysis import WaporAnalysis\r\n",
    "from waterpip.scripts.support.vector import records_to_shapefile\r\n",
    "print('class imported succesfully, you are at the starting line')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 2. Get a download token from the WAPOR website if not already done\r\n",
    "\r\n",
    "Get your API Token from https://wapor.apps.fao.org/profile, once you have it you pass it as an argument below when intiating the class\r\n",
    "as api_token='<your_token_goes_here>' . Remember to use '' so that it is recognized as a string object"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 3. Initiate/activate the class **WaporAnalysis**. \r\n",
    "\r\n",
    "**Background info**: \r\n",
    "\r\n",
    "the class **WaporAnalysis** is used to calculate performance indicators for areas specified using a shapefile. To allow access to the wapor data it uses (inherits) **WaporRetrieval** the class that allows access to the wapor portal in the waterpip package.<br> \r\n",
    "\r\n",
    "- NOTE: **WaporRetrieval** itself is built on top of (inherits) the class **WaporAPI** originally written by Bich Tran at IHE Delft for the various open source WAPOR packages released by IHE DELFT. It is a great package for accessing the WAPOR data via API and if you want more flexibility in your implementation or if you want to dive into the code directly; I recommend you check out the original code available via their packages on GIT. You can also check out the edited version of their **WaporAPI** class that can be found in this package.\r\n",
    "\r\n",
    "### **Activating the class**:\r\n",
    "\r\n",
    "to intiate the class you need to enter/edit the following inputs below:<br>\r\n",
    "\r\n",
    "- NOTE: Initiation of **WaporAnalysis** is exactly the same as **WaporRetrieval** except that datacomponents are not required as the datacomponents needed for each \r\n",
    "PAI are known.<br>\r\n",
    "\r\n",
    "    if you wish to add the datacomponents it can be done after activating the class. As you can also use it to download data. However if your are using wapor analysis to download data you can also use **WaporRetrieval**. \r\n",
    "\r\n",
    "#### Required Inputs:\r\n",
    "\r\n",
    "- **waterpip_directory**: path to the directory where the project specific directory will be created. the class *WaporRetrieval* automatically creates a new directory using the input *project_name* on activation and creates subfolders to organise the data as well. The functions that follow automatically use these folders.<br><br> \r\n",
    "\r\n",
    "- **shapefile_path**: the shapefile is a needed input that specifies the location to download data for as well as the projection to output it in. Directly the input is the path to the shapefile itself. The function retrieves the data for the area(s) shown in the shapefile.<br>\r\n",
    "\r\n",
    "    - **Note**: A shapefile is required and provides alot of the required info for the project including the extent and the output projection. Any projection (crs) is accepted, wapor data is  always downloaded in epsg: 4326 and the shapefile bounding box is transformed as needed to match. transformations are made again while retrieving the data if needed to match the projection (crs) of the input shapefile.<br><br>  \r\n",
    "\r\n",
    "- **wapor_level**: level of WAPOR data to download. There are 3 levels from low resolution 250m (1) and mid resolution 100m (2) to high resolution 30m (3). All of Africa and part of the middle east is available at level 1. Specific countries are available at level 2. Only some specific locations around the size of valleys or hydrosheds are available at level 3. For more info on the levels please see: https://wapor.apps.fao.org/home/WAPOR_2/1. <br> \r\n",
    "\r\n",
    "    - **Note**: A spatial check is carried out on the download area specified in your shapefile to see if data is available for it at the given level when running (only level 1 and 3 spatial checks exist currently). Error messages provide details.<br><br> \r\n",
    "\r\n",
    "- **api_token**: the api token retrieved form the WAPOR site goes here. see the instructions above on how to retrieve a token from the WAPOR website.<br><br>\r\n",
    "\r\n",
    "#### Optional Inputs:\r\n",
    "\r\n",
    "The following inputs are optional. They can also be provided too many of the class functions when running them. \r\n",
    "\r\n",
    "The advantage of passing them during class setup/initialisation is that it is easy to repeatedly use the class functions with the same parameters and inputs. That way you are assured it will always run the same. \r\n",
    "\r\n",
    "The advantage of passing the class functions when running the functions is that it is flexible. by changing a few of the optional class inputs you can retrieve different sets of data each time you run a function while maintaining the required class structure (folder structure, wapor level, area of interest (shapefile) and api token). \r\n",
    "\r\n",
    "- **project_name**: name of the directory that will be created, all data retrieved and analysed can be found in here, auto set to *test* if not provided.<br><br> \r\n",
    "\r\n",
    "- **period_start**: date you want to start your data download from, enter as a datetime object. This can also be provided later when running the class functions. Auto sets to 30 days before the day of running the code if not provided.<br><br> \r\n",
    "\r\n",
    "- **period_end**: date you want to end your data download at, enter as a datetime object. This can also be provided later when running the class functions. Auto sets to the day of running if not provided. <br>\r\n",
    "\r\n",
    "    - **datetime objects**: A specific way of formatting dates for python. It is made up of the function datetime followed by the date in brackets split into the sections: Year (4 digits), month (2 or 1 digit), day (2 or 1 digits). (google python datetime object for more details)<br>\r\n",
    "\r\n",
    "        - *Example*: November 4th 2020 or 4-11-2020: datetime(2020,11,4)<br>\r\n",
    "\r\n",
    "        - *Note*: do not use leading zeros for single digit dates (1 not 01).<br><br>  \r\n",
    "\r\n",
    "- **return_period**: return period to download data for, given as a single letter code. available periods include: I: Daily, D: Dekadal, S: Seasonal, A: Annual (yearly). This can also be provided later when running the class functions. Auto sets to the Dekadal (D) if not provided.<br><br> \r\n",
    "\r\n",
    "- **silent**: boolean option automatically set to False. If set to True the more general messages shared with the user when running the class will be turned off.<br><br> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# activation of the wapor analysis class \r\n",
    "analysis = WaporAnalysis(            \r\n",
    "    waterpip_directory=r'directory to store your projects',\r\n",
    "    shapefile_path=r\"path to the shapefile containing the analysis area\",\r\n",
    "    wapor_level=3,\r\n",
    "    project_name='name for the project specific folder',\r\n",
    "    api_token='your api token goes here')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 4. Create a crop mask file for use during analysis\r\n",
    "\r\n",
    "Most of the functions in **WaporAnalysis** require a field raster mask and a matching field shapefile (shapefile with a unique id per field) to function.<br>\r\n",
    "\r\n",
    "You can provide these yourself if you wish, make sure you have a shapefile that contains a unique id per polygon (field) in it and a matching 0,1 raster mask.<br>\r\n",
    "\r\n",
    "alternatively we provide two functions that can be used to create the neccescary shapefile and raster:<br> \r\n",
    "\r\n",
    "below is a description of each, you can choose whichever one you want to use:\r\n",
    "\r\n",
    "#### What both masking functions have in common:\r\n",
    "\r\n",
    "Both functions provided are from the class **WaporRetrieval** that is inherited by **WaporAnalysis**. Output from both functions is stored in a mask subfolder in the reference folder of the project directory. The user has to provide a mask name to create the folder and name the mask files:\r\n",
    "\r\n",
    "- *<user_specified_waterpip_directory>/<user_specified_project_name>/ <br>l<user_specified_wapor_level>/00_reference/<mask_name>/* \r\n",
    "\r\n",
    "a new shapefile is made in both cases and stored here as well as the raster mask produced. The new shapefile will also contain an automatically generated id column called *wpid* that holds a unique id per polygon. a unique id column is required when calculating zonal statistics.\r\n",
    "\r\n",
    "**create_raster_mask_from_shapefile**: The function creates a new shapefile and a mask based off a shapefile that the user provides. Of the two methods this is the most reliable as the user determines where the polygons (fields are). If you are certain that your polygons are correct this way is best. The function generates a unique id named *wpid* per polygon and uses the shapefile to generate a matching mask.\r\n",
    "\r\n",
    "**create_raster_mask_from_wapor_LCC**: The second function uses the land cover classification rasters available via the WAPOR portal too  generate the mask files by masking to the categories (crops etc) specified by the user and vectorizing the result. The categories given are also attached to the shapefile as a new column. \r\n",
    "\r\n",
    "- NOTE: It is recommended you se one of the two methods as it prevents alteration of your original files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "NOTE: If masking using a WAPOR LCC raster you can skip this step and follow step 4.2\r\n",
    "\r\n",
    "### 4.1 Using a user defined shapefile to produce a mask<br>\r\n",
    "\r\n",
    "In detail this function uses the shapefile given by the user in combination with a template raster (if not provided by the user this is retrieved from the wapor portal) to create a new shapefile and raster mask as described above<br>\r\n",
    "\r\n",
    "#### Required Inputs:<br>\r\n",
    "\r\n",
    "- **mask_name**: name used in the mask files generated and it is also the name given to the mask subfolder generated.<br>\r\n",
    "\r\n",
    "    - WARNING: the mask name given here needs to be provided as the input for the mask_folder input when running other **WaporAnalysis** functions. (**IMPORTANT**)<br>\r\n",
    "\r\n",
    "#### Optional Inputs:<br>\r\n",
    "\r\n",
    "- **input_shapefile_path**: path to the shapefile holding the fields/polygons that will be masked too.<br>\r\n",
    "\r\n",
    "    - NOTE: This is only optional as you can also use the shapefile privded on activation of the class **WaporAnalysis** (this is automatcally selected if no shapefile is provided).<br><br>\r\n",
    "\r\n",
    "- **template_raster_path**: path to the raster used as a template. The raster provides the metadata (dimensions, resolution etc) used to make the raster mask. if not provided the input shapefile is used to retrieve a random raster from the wapor portal to use as a template (the raster retrieved will match the area and wapor level requirements).<br> \r\n",
    "\r\n",
    "#### Output:\r\n",
    "\r\n",
    "- a tuple containing the path to the mask raster created and the path to the mask shapefile created"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# method one using the shapefile (if not using this method skip this cell)\r\n",
    "mask_raster_path, mask_shape_path = analysis.create_raster_mask_from_shapefile(\r\n",
    "        mask_name='name for the mask')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "NOTE: If masking using your own shapefile please follow the step 4.1\r\n",
    "\r\n",
    "### 4.2 Using a WAPOR land cover classification (LCC) raster to produce a mask\r\n",
    "\r\n",
    "In detail this function retrieves all the land cover classification rasters available within the period specified by the user at the interval specified by the user and within the area specified by the shapefile given by the user. \r\n",
    "\r\n",
    "The retrieved LCC rasters are then used to calculate the most commonly occurring category per cell across time from all the retreived rasters  producing a most common land classification raster for that period (this whole step is skipped if only one LCC raster is found). <br> \r\n",
    "\r\n",
    "this raster is then masked to the categories provided by the user maintaining the values in the unmasked cells. This raster is then also masked to 0,1. This is considered the raw mask file.<br> \r\n",
    "\r\n",
    "The values raster is vectorized to produce a raw mask shapefile of the fields. The categories are added as a column to the shapefile.<br> \r\n",
    "\r\n",
    "As a secondary step this shapefile is cleaned up (the geometries filtered and fixed to produce a new shapefile containing geometries that may better fit the fields)<br> \r\n",
    "\r\n",
    "Lastly the cleaned shapefile is rasterized to produce a matching 'cleaned'mask.<br> \r\n",
    "\r\n",
    "It is up to the user to select either the 'raw' or 'cleaned' combination of files to use during the analysis. Wether the cleaned file is better than the raw file is subjective.<br>  \r\n",
    "\r\n",
    "#### Required Inputs:<br>\r\n",
    "\r\n",
    "- **mask_name**: name used in the mask files generated and it is also the name given to the mask subfolder generated.<br>\r\n",
    "\r\n",
    "    - WARNING: the mask name given here needs to be provided as the input for the mask_folder input when running other **WaporAnalysis** functions. (**IMPORTANT**)<br><br>\r\n",
    "\r\n",
    "- **lcc_categories**: list of crops/land classification categories to mask. Categories have to match those used in the wapor database land cover classification codes exactly. If not a list of options will be returned as an error.<br>\r\n",
    "\r\n",
    "    - NOTE: In the case that the categories given do not exist in the area an error will be raised sharing the categories that are available<br><br>\r\n",
    "\r\n",
    "    - NOTE: Some aggregate categories are also being developed to speed up the process such as all crops. All crop categoires are then retrieved if this argument is provded (**in development**).<br>\r\n",
    "\r\n",
    "#### Optional Inputs:<br>\r\n",
    "\r\n",
    "- **input_shapefile_path**: path to the shapefile holding the fields/polygons that will be masked too.<br>\r\n",
    "\r\n",
    "    - NOTE: This is only optional as you can also use the shapefile privded on activation of the class **WaporAnalysis** (this is automatcally selected if no shapefile is provided).<br><br>\r\n",
    "\r\n",
    "- **period_start**: date you want to start your data download from, enter as a datetime object. Uses the period_start set when initalising the class if not provided.<br><br> \r\n",
    "\r\n",
    "- **period_end**: date you want to end your data download at, enter as a datetime object. Uses the period_start set when initalising the class if not provided. <br>\r\n",
    "\r\n",
    "    - NOTE: see the class description in step 3 for details on datetime formatting<br><br>\r\n",
    "\r\n",
    "- **area_threshold_multiplier**: area threshold with which to filter out too small polygons when cleaning up the raw shapefile  (single cell area * area_threshold_multiplier sets the threshold)<br>\r\n",
    "\r\n",
    "    - WARNING: for level 3 the area_threshold_multiplier is set to a minimum of 1.5, you have to alter the code to change this<br><br>\r\n",
    "\r\n",
    "- **output_nodata**: nodata value to use for the all rasters made aside from the 0,1 mask rasters auto set to -9999<br>\r\n",
    "\r\n",
    "#### Output:<br>\r\n",
    "\r\n",
    "- a tuple containing the path to the mask raster created and the path to the mask shapefile created<br>\r\n",
    "\r\n",
    "    - NOTE: the paths to the raw files made are not returned but they can be foudn in the same location as the files specified above<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create corp mask using the land classification raster from wapor (if not using this method please use the one above and skip this cell)\r\n",
    "mask_raster_path2, mask_shape_path2 = analysis.create_raster_mask_from_wapor_lcc(\r\n",
    "    lcc_categories=['irrigated sugar cane','sugarcane'],\r\n",
    "    mask_name='name for the mask again',\r\n",
    "    period_start=datetime(2020,3,5),\r\n",
    "    period_end=datetime(2020,4,5),\r\n",
    "    area_threshold_multiplier=2 # used to remove too small areas\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 4.3 Check out the mask raster and shapefile created (if you like)\r\n",
    "\r\n",
    "take the time to check out the mask raster and shapefile you have prodcuced in QGIS or ArcGIS etc if you like"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print out the paths to the files produced\r\n",
    "print('mask shapefile:{}\\n'.format(mask_raster_path))\r\n",
    "\r\n",
    "print('mask shapefile:{}'.format(mask_shape_path))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 5. Calculate WAPOR based PAIs \r\n",
    "\r\n",
    "Once you have intitiated the class **WaporAnalysis** and you have a mask raster and shapefile with a unique id column it is possible to calculate PAIs using WaPOR data. <br>\r\n",
    "\r\n",
    "This is possible for the following PAI's:<br>\r\n",
    "\r\n",
    "    - beneficial fraction (bf): measure of efficiency\r\n",
    "    \r\n",
    "        - formula: Sum of Transpiration  / Sum of Evapotranspiration \r\n",
    "\r\n",
    "    - coeffecient of variation (cov): measure of equity\r\n",
    "    \r\n",
    "        - formula: standard deviation of summed Evapotranspiration per field / mean of summed evapotranspiration per field \r\n",
    "\r\n",
    "    - crop_water_deficit (cwd): measure of adequacy \r\n",
    "    \r\n",
    "        formula: Potential evapotranspiration - Sum of Evapotranspiration \r\n",
    "    \r\n",
    "    - relative evapotranspiration (ret): measure of adequacy\r\n",
    "    \r\n",
    "        - formula: Sum of Evapotranspiration / Potential evapotranspiration \r\n",
    "    \r\n",
    "    - temporal relative evapotranspiration (tret): measure of reliability\r\n",
    "    \r\n",
    "        - formula: per dekad (or other period) Sum of Evapotranspiration / Potential evapotranspiration \r\n",
    "\r\n",
    "Each PAI function can be considered a small processing chain/pipeline in and of itself as it calls on multiple subfunctions to do its task in a organized manner. Each of those sub functions can also be called on their own if you want to run them seperatly or set up your won pipeline. Check out and dive into the code for more details.\r\n",
    "\r\n",
    "Each PAI can be calculated seperately by calling on their specific function such as crop water deficit: *calc_crop_water_deficit*. Or all of them can be calculated in one go by using the function: *calc_wapor_performance_indicators* \r\n",
    "\r\n",
    "In the example below we will calculate relative evapotranspiration.\r\n",
    "\r\n",
    "\r\n",
    "to run the **WaporAnalysis** class function *calc_relative_evapotranspiration* you need to provide the following inputs:\r\n",
    "\r\n",
    "#### Required Inputs:\r\n",
    "\r\n",
    "- **mask_raster_path**: path to a mask raster to mask output too, asl acts as the template raster for the crs, resolution and dimensions of any output rasters etc. (this can be provided by using the mask functions described above).<br><br>\r\n",
    "\r\n",
    "- **mask_folder**: ame to use for the mask folder auto set to nomask if not provided.<br>\r\n",
    "\r\n",
    "    - WARNING: If using a mask generated by the internal mask functions this input should match the *mask_name* input provided there. (**IMPORTANT**)<br>\r\n",
    "\r\n",
    "#### Optional Inputs:\r\n",
    "\r\n",
    "- **period_start**: date you want to start your data download from (period of analsyis such as a growth season), enter as a datetime object. This could also have been provided when intitiating the class.<br><br>\r\n",
    "\r\n",
    "- **period_end**: date you want to end your data download at (period of analsyis such as a growth season), enter as a datetime object. This could also have been provided when intitiating the class.<br>\r\n",
    "\r\n",
    "    - NOTE: see the class explanation above for more details on *datetime objects*<br><br>\r\n",
    "\r\n",
    "- **return_period**: return period to download data for, given as a single letter code. available periods include: I: Daily, D: Dekadal, S: Seasonal, A: Annual (yearly). This could also have been provided when intitiating the class.<br><br>\r\n",
    "\r\n",
    "- **percentile**: percentile of evapotranspiration values to choose as the potential evapotranspiration value (potet calculated is relative not absolute)<br><br>\r\n",
    "\r\n",
    "- **id_key**: name of the shapefile column key providing the feature indices.  wpid is a reliable autogenerated index provided while making the in house mask<br><br>\r\n",
    "\r\n",
    "- **fields_shapefile_path**: if the path to the fields shapefile path is provided then the field level statistics are also calculated otherwise only the raster is produced<br><br>\r\n",
    "\r\n",
    "- **field_stats**: list of statistics to carry out during the field level analysis, also used in the column names  <br><br>\r\n",
    "\r\n",
    "- **out_dict**: boolean option if True outputs a dict if False outputs a dataframe if a field level statistics are calculated. auto set to False<br><br>\r\n",
    "\r\n",
    "- **output_nodata**: nodata value to use for the retrieved rasters auto set to -9999<br><br>\r\n",
    "\r\n",
    "#### Output:\r\n",
    "\r\n",
    "- a  tuple that holds the path to the relative evapotranspiration raster. the second half of the tuple is none if no field level statistics are calculated. If they are it is another tuple the first half of which holds the dataframe/dict produced and the second half the path to the csv of field statistics\r\n",
    "\r\n",
    "\r\n",
    "      "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "outputs = analysis.calc_relative_evapotranspiration(\r\n",
    "    period_start=datetime(2020,3,5), \r\n",
    "    period_end=datetime(2020,4,5),\r\n",
    "    fields_shapefile_path=mask_shape_path2,\r\n",
    "    mask_raster_path=mask_raster_path2,\r\n",
    "    mask_folder='name of the mask again',\r\n",
    "    output_nodata=-9999,\r\n",
    "    )\r\n",
    "\r\n",
    "# organise the outputs:\r\n",
    "\r\n",
    "# paths to the raster created\r\n",
    "pai_ret_raster_path = outputs[0]\r\n",
    "print(pai_ret_raster_path)\r\n",
    "\r\n",
    "# dataframe created\r\n",
    "pai_ret_df = outputs[1][0]\r\n",
    "print(pai_ret_df)\r\n",
    "\r\n",
    "# path to the csv created\r\n",
    "pai_ret_csv = outputs[1][1]\r\n",
    "print(pai_ret_csv)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## 6. Output to shapefile\r\n",
    "\r\n",
    "As a last step we can output the calculated PAI statistics too shapefile so that it can be visualised in QGIS or ArcGIS as the user wants.<br>\r\n",
    "\r\n",
    "**Required Inputs**:<br>\r\n",
    "\r\n",
    "- **records**: the dictionary or dataframe contain the records/info that is to be outputted to shapefile.<br><br>\r\n",
    "\r\n",
    "- **output_shapefile_path**: path to output the created shapefile too<br><br>\r\n",
    "\r\n",
    "- **fields_shapefile_path**: path to the shapefile holding the reference fields/geometries to which the data should be attached. For exmaple the input shapefiel used to generate the data, or the reference shapefile generated by the crop maks function of wapor analysis.<br><br> \r\n",
    "\r\n",
    "- **union_key**: identifies the column in the *fields_shapefile_path*  and in the records used to combine the too. if workign with a shapefiel generated by the crop maks script 'wpid' is suggested. otherwise another column/key can also be used.<br>\r\n",
    "\r\n",
    "**Optional Inputs**:<br>\r\n",
    "\r\n",
    "- **output_crs**: if provided warps the shapefile to match this crs<br><br>\r\n",
    "\r\n",
    "WARNING: long column names (like those currently autogenerated in the creation of pai csvs/excels will be truncated, use the csv to match which column is which or edit the csv to have shorter column names)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "records_to_shapefile(\r\n",
    "    records=pai_ret_df, # dataframe holding the statds too output\r\n",
    "    output_shapefile_path=r\"path to output shapefile too goes here\",\r\n",
    "    fields_shapefile_path=mask_shape_path2,\r\n",
    "    union_key=\"wpid\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6 Check out the data \r\n",
    "if the code ran succesfully you should be able to find some results in the folder: \r\n",
    "*<wapor_directory>/<project_name>/L<number>/04_results*\r\n",
    "\r\n",
    "## 7 Visualise the data\r\n",
    "\r\n",
    "You can check the data using a program such as Qgis or arcGIS or however you want.\r\n",
    "\r\n",
    "## 8 Rinse and Repeat  \r\n",
    "\r\n",
    "Now that you know how to retrieve data and analyse data feel free to repeat the notebooks *04_waterpip_analysis_PAIs* and play around with the parameters. If you feel like it you can even get into the code itself and see what you can code, run, retrieve and analyse! \r\n",
    "\r\n",
    "## 9 Visualising Performance Assessment Indicators (PAIs) for an area\r\n",
    "\r\n",
    "If you feel like it you can also take a look at notebook *05_visualising_waterpip_results.ipynb* where we walk you through the process of producing some more informative visualisations and graphs from some of your previously downloaded data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb6e41edeab3f42d50ea9236dcecac736897217ffa96627c5a1495551deefd30"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('waterpip': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}